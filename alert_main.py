import requests
import pandas as pd
import numpy as np # [ì†ë„ í–¥ìƒ í•µì‹¬]
import time
import os
import json
from datetime import datetime

# ==========================================
# [ì„¤ì •] ì¸ì¦í‚¤, ìŠ¬ë™ URL
# ==========================================
service_key = os.environ.get("DATA_API_KEY")
slack_webhook_url = os.environ.get("SLACK_WEBHOOK_URL")
base_url = f"http://apis.data.go.kr/B552584/EvCharger/getChargerInfo?serviceKey={service_key}"

# íŒŒì¼ ê²½ë¡œ
skel_file_path = "skel_chargers.csv"
history_file_path = "competitor_alerts.csv"
prev_data_path_gz = "latest_data.csv.gz"
prev_data_path_csv = "latest_data.csv"

# ì „êµ­ ì§€ì—­ì½”ë“œ
zcodes = [
    '11', '26', '27', '28', '29', '30', '31', '36', 
    '41', '43', '44', '46', '47', '48', '50', '51', '52'
]

# ==========================================
# [ë§¤í•‘ ë° í•¨ìˆ˜]
# ==========================================
REGION_MAP = {
    '11': 'ì„œìš¸íŠ¹ë³„ì‹œ', '26': 'ë¶€ì‚°ê´‘ì—­ì‹œ', '27': 'ëŒ€êµ¬ê´‘ì—­ì‹œ', '28': 'ì¸ì²œê´‘ì—­ì‹œ',
    '29': 'ê´‘ì£¼ê´‘ì—­ì‹œ', '30': 'ëŒ€ì „ê´‘ì—­ì‹œ', '31': 'ìš¸ì‚°ê´‘ì—­ì‹œ', '36': 'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ',
    '41': 'ê²½ê¸°ë„', '43': 'ì¶©ì²­ë¶ë„', '44': 'ì¶©ì²­ë‚¨ë„', '46': 'ì „ë¼ë‚¨ë„',
    '47': 'ê²½ìƒë¶ë„', '48': 'ê²½ìƒë‚¨ë„', '50': 'ì œì£¼íŠ¹ë³„ìì¹˜ë„', '51': 'ê°•ì›íŠ¹ë³„ìì¹˜ë„',
    '52': 'ì „ë¶íŠ¹ë³„ìì¹˜ë„'
}

BUSI_MAP = {'ME': 'í™˜ê²½ë¶€', 'LU': 'LGìœ í”ŒëŸ¬ìŠ¤', 'SG': 'ì‹œê·¸ë„·', 'KP': 'í•œêµ­ì „ë ¥'} 

def classify_region(code):
    code = str(code)
    if code in ['11', '28', '41']: return 'ìˆ˜ë„ê¶Œ'
    elif code in ['26', '27', '29', '30', '31']: return '5ëŒ€ê´‘ì—­ì‹œ'
    else: return 'ì§€ë°©'

def classify_charger_newtype(row):
    c_type = str(row.get('chgerType', '')).strip()
    output = str(row.get('output', '')).strip()
    slow_types = ['02', '07', '08']
    fast_check_types = ['01', '03', '04', '05', '06', '09', '10']
    
    if c_type in slow_types: return "ì™„ì†"
    elif (c_type in fast_check_types) and (output == "30"): return "ì™„ì†"
    else: return "ê¸‰ì†"

def get_capacity_value(row):
    try:
        output_val = float(str(row.get('output', 0)).replace(',', '').strip())
    except:
        output_val = 0.0
    method_str = str(row.get('method', '')).strip()
    factor = 0.5 if 'ë™ì‹œ' in method_str else 1.0
    return output_val * factor

def send_slack_alert(message):
    if not slack_webhook_url:
        print("âš ï¸ ìŠ¬ë™ ì›¹í›… ì—†ìŒ")
        return
    try: requests.post(slack_webhook_url, json={"text": message})
    except: pass

# [í•µì‹¬] ê³ ì† ê±°ë¦¬ ê³„ì‚° í•¨ìˆ˜ (NumPy ë²¡í„°í™”)
def calculate_distance_vectorized(lat1, lon1, lat2_series, lon2_series):
    R = 6371
    dlat = np.radians(lat2_series - lat1)
    dlon = np.radians(lon2_series - lon1)
    a = np.sin(dlat/2)**2 + np.cos(np.radians(lat1)) * np.cos(np.radians(lat2_series)) * np.sin(dlon/2)**2
    c = 2 * np.arcsin(np.sqrt(a))
    return R * c

# ==========================================
# 0. ì¸ì¦í‚¤ í™•ì¸
# ==========================================
if not service_key:
    print("âŒ API ì¸ì¦í‚¤ ì—†ìŒ")
    exit()

# ==========================================
# 1. ì˜¤ëŠ˜ ë°ì´í„° ìˆ˜ì§‘ (ì¬ì‹œë„ ë¡œì§ ê°•í™”)
# ==========================================
all_data = []
print("ğŸ“¡ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (ì•ˆì •ì„± ê°•í™” ëª¨ë“œ)")

for zcode in zcodes:
    page_no = 1
    
    while True:
        # [í•µì‹¬] 3ë²ˆê¹Œì§€ ì¬ì‹œë„ (Retry Logic)
        success = False
        for attempt in range(3):
            try:
                # íƒ€ì„ì•„ì›ƒ 30ì´ˆë¡œ ë„‰ë„‰í•˜ê²Œ ì„¤ì •
                res = requests.get(base_url, params={"pageNo": page_no, "numOfRows": "9999", "zcode": zcode, "dataType": "JSON"}, timeout=30)
                
                if res.status_code == 200:
                    try:
                        data = res.json()
                        items = data.get('items', {}).get('item', [])
                        if isinstance(items, dict): items = [items]
                        
                        # ì•„ì´í…œì´ ì—†ìœ¼ë©´ í•´ë‹¹ ì§€ì—­ ìˆ˜ì§‘ ì¢…ë£Œ (ì •ìƒ)
                        if not items:
                            success = True
                            break 
                        
                        all_data.extend(items)
                        print(f"ì§€ì—­ {zcode} - {page_no}í˜ì´ì§€: {len(items)}ê±´ ìˆ˜ì§‘")
                        
                        if len(items) < 9999:
                            # ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬
                            page_no = -1 # ë£¨í”„ ì¢…ë£Œ ì‹ í˜¸
                        else:
                            page_no += 1 # ë‹¤ìŒ í˜ì´ì§€
                        
                        success = True
                        break # ì„±ê³µí–ˆìœ¼ë¯€ë¡œ ì¬ì‹œë„ ë£¨í”„ íƒˆì¶œ
                        
                    except json.JSONDecodeError:
                        print(f"âš ï¸ JSON íŒŒì‹± ì—ëŸ¬ (ì§€ì—­ {zcode}, í˜ì´ì§€ {page_no}) - ì¬ì‹œë„ {attempt+1}/3")
                        time.sleep(2)
                else:
                    print(f"âš ï¸ ì„œë²„ ì—ëŸ¬ {res.status_code} (ì§€ì—­ {zcode}) - ì¬ì‹œë„ {attempt+1}/3")
                    time.sleep(3)
            except Exception as e:
                print(f"âš ï¸ ì—°ê²° ì—ëŸ¬: {e} (ì§€ì—­ {zcode}) - ì¬ì‹œë„ {attempt+1}/3")
                time.sleep(3)
        
        # 3ë²ˆ ë‹¤ ì‹¤íŒ¨í–ˆê±°ë‚˜, ë§ˆì§€ë§‰ í˜ì´ì§€(-1)ì¸ ê²½ìš° ì²˜ë¦¬
        if not success:
            print(f"âŒ ì§€ì—­ {zcode} {page_no}í˜ì´ì§€ ìˆ˜ì§‘ ì‹¤íŒ¨. ë‹¤ìŒ ì§€ì—­ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
            break
        
        if page_no == -1:
            break
            
        time.sleep(0.2) # ì„œë²„ ë¶€í•˜ ë°©ì§€ìš© ì§§ì€ ëŒ€ê¸°

if not all_data:
    print("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤.")
    exit()

print(f"âœ… ì´ {len(all_data)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ!")

df = pd.DataFrame(all_data)

# ê°€ê³µ
df['ê¶Œì—­'] = df['zcode'].apply(classify_region)
df['ì§€ì—­ëª…'] = df['zcode'].map(REGION_MAP).fillna(df['zcode'])
df['ìš´ì˜ê¸°ê´€(ê°€ê³µ)'] = df['busiId'].map(BUSI_MAP).fillna(df['busiNm'])
df['newtype'] = df.apply(classify_charger_newtype, axis=1)
df['lat'] = pd.to_numeric(df['lat'], errors='coerce')
df['lng'] = pd.to_numeric(df['lng'], errors='coerce')
df['calc_capacity'] = df.apply(get_capacity_value, axis=1)

# ì»¬ëŸ¼ ì •ë¦¬
cols = df.columns.tolist()
front = ['ê¶Œì—­', 'ì§€ì—­ëª…', 'ìš´ì˜ê¸°ê´€(ê°€ê³µ)', 'newtype', 'statNm', 'addr', 'chgerType', 'output']
final = [c for c in front if c in cols] + [c for c in cols if c not in front]
df = df[final]

# ì˜¤ëŠ˜ ë°ì´í„° ì €ì¥
today_str = datetime.now().strftime("%Y%m%d")
df.to_excel(f"ì „ê¸°ì°¨ì¶©ì „ì†Œ_{today_str}.xlsx", index=False)

# ==========================================
# 2. ì‹ ê·œ ê°ì§€ (ì†ë„ ê°œì„ )
# ==========================================
new_chargers_df = pd.DataFrame()
prev_df = pd.DataFrame()

# [ì†ë„ ê°œì„ ] low_memory=Falseë¡œ ë¡œë”©
if os.path.exists(prev_data_path_gz):
    print("ğŸ“‚ (ì••ì¶•) ì–´ì œ ë°ì´í„° ë¡œë“œ")
    prev_df = pd.read_csv(prev_data_path_gz, compression='gzip', low_memory=False)
elif os.path.exists(prev_data_path_csv):
    print("ğŸ“‚ (ì¼ë°˜) ì–´ì œ ë°ì´í„° ë¡œë“œ")
    prev_df = pd.read_csv(prev_data_path_csv, low_memory=False)

if not prev_df.empty:
    prev_ids = set(prev_df['statId'].astype(str))
    curr_ids = set(df['statId'].astype(str))
    new_ids = curr_ids - prev_ids
    
    if new_ids:
        print(f"âœ¨ ì‹ ê·œ {len(new_ids)}ê°œì†Œ ë°œê²¬ (ì „ì²´ ìŠ¤ìº” ì‹œì‘)")
        new_chargers_df = df[df['statId'].astype(str).isin(new_ids)].copy()
    else:
        print("âœ… ì‹ ê·œ ì—†ìŒ")
else:
    print("âš ï¸ ë¹„êµ íŒŒì¼ ì—†ìŒ -> ì „ì²´ ë°ì´í„°ë¥¼ ëŒ€ìƒìœ¼ë¡œ ë¶„ì„ (ìµœì´ˆ ì‹¤í–‰)")
    new_chargers_df = df.copy()

# ==========================================
# 3. ê±°ë¦¬ ê³„ì‚° (ë²¡í„°í™” + ê·¸ë£¹í•‘)
# ==========================================
alert_list = []
history_records = []
today_dash = datetime.now().strftime("%Y-%m-%d")

if not new_chargers_df.empty and os.path.exists(skel_file_path):
    skel_df = pd.read_csv(skel_file_path)
    
    # 1. ì‹ ê·œ ì¤‘ 'ê¸‰ì†'ë§Œ í•„í„°ë§
    targets = new_chargers_df[new_chargers_df['newtype'] == 'ê¸‰ì†'].copy()
    
    if not targets.empty:
        # 2. [ë¡œì§ ê°œì„ ] statId ê¸°ì¤€ ê·¸ë£¹í•‘ (ìš©ëŸ‰ í•©ì‚°, ì¤‘ë³µ ì œê±°)
        agg_rules = {
            'calc_capacity': 'sum',
            'statNm': 'first', 'ìš´ì˜ê¸°ê´€(ê°€ê³µ)': 'first',
            'addr': 'first', 'lat': 'first', 'lng': 'first'
        }
        grouped_targets = targets.groupby('statId', as_index=False).agg(agg_rules)
        
        print(f"ğŸš€ ë¶„ì„ ëŒ€ìƒ: {len(grouped_targets)}ê°œ ì¶©ì „ì†Œ (ê³ ì† ê³„ì‚° ì¤‘...)")
        
        # 3. [ì†ë„ ê°œì„ ] SKEL ì§€ì  ë£¨í”„ + ë²¡í„°í™” ê±°ë¦¬ ê³„ì‚°
        for _, skel in skel_df.iterrows():
            s_lat, s_lng = skel.get('lat'), skel.get('lng')
            if pd.isna(s_lat) or pd.isna(s_lng): continue

            # NumPyë¥¼ ì´ìš©í•œ ê³ ì† ê±°ë¦¬ ê³„ì‚°
            distances = calculate_distance_vectorized(s_lat, s_lng, grouped_targets['lat'], grouped_targets['lng'])
            
            # 1km ì´ë‚´ ì¸ë±ìŠ¤ ì¶”ì¶œ
            nearby_indices = np.where(distances <= 1.0)[0]
            
            for idx in nearby_indices:
                dist = distances[idx]
                comp = grouped_targets.iloc[idx]
                
                alert_info = {
                    "skel_name": skel['statNm'], "dist": f"{dist:.3f}km",
                    "comp_name": comp['statNm'], "comp_busi": comp['ìš´ì˜ê¸°ê´€(ê°€ê³µ)'],
                    "output": comp['calc_capacity'], "addr": comp['addr']
                }
                alert_list.append(alert_info)
                
                history_records.append({
                    "ê°ì§€ì¼ì": today_dash,
                    "SKEL_ID": skel.get('statId', 'Unknown'), "SKEL_ì§€ì ëª…": skel.get('statNm', 'Unknown'),
                    "ê±°ë¦¬(km)": round(dist, 3), 
                    "ê²½ìŸì‚¬_ID": comp['statId'], "ê²½ìŸì‚¬_ì§€ì ëª…": comp['statNm'],
                    "ìš´ì˜ì‚¬": comp['ìš´ì˜ê¸°ê´€(ê°€ê³µ)'], "ì´ìš©ëŸ‰": comp['calc_capacity'],
                    "ê²½ìŸì‚¬_ì£¼ì†Œ": comp['addr']
                })
        print("âœ… ê±°ë¦¬ ê³„ì‚° ì™„ë£Œ")

# ê²°ê³¼ ì €ì¥
if history_records:
    new_h = pd.DataFrame(history_records)
    if os.path.exists(history_file_path):
        old_h = pd.read_csv(history_file_path)
        final_h = pd.concat([old_h, new_h], ignore_index=True)
    else: final_h = new_h
    final_h.to_csv(history_file_path, index=False, encoding='utf-8-sig')

# ìŠ¬ë™ ì „ì†¡
if alert_list:
    msg = f"ğŸš¨ *[ê²½ìŸì‚¬ ì§„ì…] SKEL ë°˜ê²½ 1km ë‚´ ({today_dash})*\nì´ {len(alert_list)}ê±´ ê°ì§€\n\n"
    for item in alert_list[:15]:
        msg += f"ğŸ“ *{item['skel_name']}* ì¸ê·¼ ({item['dist']})\n â€¢ {item['comp_name']} ({item['comp_busi']}) / ì´ {item['output']}kW\n"
    if len(alert_list) > 15:
        msg += f"\n...ì™¸ {len(alert_list)-15}ê±´ (ì—‘ì…€ í™•ì¸)"
    send_slack_alert(msg)

# ë°ì´í„° ì••ì¶• ì €ì¥
df.to_csv(prev_data_path_gz, index=False, compression='gzip', encoding='utf-8-sig')
print(f"ğŸ’¾ ë°ì´í„° ê°±ì‹  ì™„ë£Œ: {prev_data_path_gz}")

if os.path.exists(prev_data_path_csv):
    try: os.remove(prev_data_path_csv)
    except: pass
